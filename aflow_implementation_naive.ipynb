{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffac8e67",
   "metadata": {},
   "source": [
    "# ${Aflow}$ Implementation experiments\n",
    "\n",
    "## Source\n",
    "* https://arxiv.org/pdf/2410.10762\n",
    "\n",
    "## Notes\n",
    "* Use gpt-4o-mini as executor/workflow constructor (executor/optimizer)\n",
    "* backprop through modifications (?) that are descriptions for the executor to implement onto the parent\n",
    "     * therefore need a way to modify the parent via text\n",
    "\n",
    "## Algorithm\n",
    "* Split data into 20% val/80% training\n",
    "* $async$ Get scores for initial workflow on val data\n",
    "* Pare down val data to examples with high score variance (above threshold)\n",
    "* set $experiences = []$\n",
    "* set $allresults = []$\n",
    "* set $topkW = []$\n",
    "* set $W^* = None$\n",
    "* set $topkScores = []$\n",
    "* set $bestScore = 0$\n",
    "\n",
    "* for each training step,\n",
    "    * set parent as initial workflow for first step or select parent from last training step results using subroutine ${SelectParent}$\n",
    "    * get the optimizer context (parent workflow + last step experiences)\n",
    "    * use the optimizer with the context and set of available operators to improve the parent workflow and generate $W_{round}$ and the ${modification}$ it's based on\n",
    "    * set $evalresults=[]$\n",
    "    * $async$ for each of 5 rounds\n",
    "        * execute $W_{round}$ on the val data and get ${score}/{cost}$ from evaluator ${E} / {G}$\n",
    "        * append the ${score},{cost}$ to $evalresults$\n",
    "    * append $evalresults$ to $allresults$\n",
    "    * calculate the average $score$ for the 5 rounds from $evalresults$\n",
    "    * create a new experience with the parent workflow, the modification to produce $W_{round}$, and the average $score$\n",
    "    * append the experience to $experiences$ \n",
    "    * if the average $score$ is higher than the $bestScore$, update $W^* = W_{round}$ and $bestScore = $ average $score$\n",
    "    * add $W_{round}$ to $topkW$ and average $score$ to $topkScores$ if $topkW$ has fewer than $k$ elements or average $score$ is greater than the lowest value in $topkScores$\n",
    "    * if $topkScores$ hasn't changed in specified (n) number of rounds, stop early and return $W^*$\n",
    "* return $W^*$\n",
    "    \n",
    "### Algorithm Unknowns\n",
    "* how to get evaluator G/E?\n",
    "* how do initial scores get computed? are there multiple rounds of scoring per example in order to generate variance samples?\n",
    "* how does the optimizer generate new workflows from previous samples (experiences)?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b28c83b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from math import e\n",
    "from random import choices,seed,random\n",
    "from uuid import uuid5 as uuid\n",
    "from uuid import NAMESPACE_DNS\n",
    "from copy import deepcopy\n",
    "from pydantic import BaseModel,conint\n",
    "from typing import List\n",
    "from tqdm.notebook import tqdm\n",
    "from tqdm.asyncio import tqdm as tqdm_asyncio\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b965f9a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# DONE: Implement create_experience\n",
    "class Experience:\n",
    "    def __init__(self,workflow,round_added,score,parent_score=None,modification=None):\n",
    "        self.workflow = workflow\n",
    "        \n",
    "        self.parent_workflow = self.workflow.parent\n",
    "        if self.parent_workflow:\n",
    "            self.parent_workflow_id = self.parent_workflow.id\n",
    "        else:\n",
    "            self.parent_workflow_id = None\n",
    "        self.parent_score = parent_score\n",
    "        \n",
    "        if modification:\n",
    "            self.round_modification_added = round_added\n",
    "            self.round_added = self.parent_workflow.round_added\n",
    "        else:\n",
    "            self.round_modification_added = None\n",
    "            self.round_added = round_added\n",
    "        \n",
    "        self.score = score\n",
    "        self.modification = modification\n",
    "        \n",
    "        if self.parent_score and (isinstance(self.parent_score,float) or isinstance(self.parent_score,int)):\n",
    "            self.success = self.score > self.parent_score\n",
    "        else:\n",
    "            self.success = None\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"\"\"\n",
    "        Experience Info:\n",
    "        Metadata:\n",
    "        - Workflow with modification ID: {self.workflow.id}\n",
    "        - Workflow with modification score: {self.score}\n",
    "        - Workflow without modification ID: {self.parent_workflow_id}\n",
    "        - Workflow without modification score: {self.parent_score}\n",
    "        \n",
    "        \n",
    "        Modification that lead to this experience:\n",
    "        - Did the modification lead to improvement over workflow without modifications: {self.success}\n",
    "        - Round Workflow was modified: {self.round_added}\n",
    "        - Modification details: {self.modification}\n",
    "        \"\"\"\n",
    "\n",
    "# DONE: Implement Experience(Experiences?) obj in a way that makes retrieval by round easier\n",
    "class Experiences:\n",
    "    def __init__(self):\n",
    "        self.experiences = {}\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        return self.experiences[key]\n",
    "        \n",
    "    def create_experience(self,workflow,round_,score,modification=None):\n",
    "        if round_ not in self.experiences:\n",
    "            self.experiences[round_] = {}\n",
    "        parent_score = None\n",
    "        if modification:\n",
    "            #print(self.experiences,round_,workflow.parent.round_added,score,modification)\n",
    "            parent_score = self.experiences[workflow.parent.round_added][workflow.parent.id].score\n",
    "        self.experiences[round_][workflow.id] = Experience(workflow,round_,score,parent_score,modification)\n",
    "        return self.experiences[round_][workflow.id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4941f12a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class WorkflowNode:\n",
    "    def __init__(self,description,prompt,modification,next_node=None):\n",
    "        self.description = description\n",
    "        self.prompt = prompt\n",
    "        self.modification = modification\n",
    "        if next_node is None:\n",
    "            self.next = FinalNode()\n",
    "        else:\n",
    "            self.next = next_node()\n",
    "        \n",
    "    def __call__(self,**kwargs):\n",
    "        #does something with prev_step and returns it\n",
    "        llm_client = kwargs['llm_client']\n",
    "        data = kwargs['data']\n",
    "        \n",
    "    def copy(self):\n",
    "        return deepcopy(self)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return ', '.join(f'{key}={value}' for key, value in vars(self).items())\n",
    "    \n",
    "class FinalNode:\n",
    "    def __init__(self):\n",
    "        self.next = None\n",
    "        self.description = 'This node is a final sentinel and simply passes what it\\'s given through.'\n",
    "        \n",
    "    async def __call__(self,**kwargs):\n",
    "        #print(kwargs)\n",
    "        return kwargs\n",
    "    \n",
    "    def copy(self):\n",
    "        return self\n",
    "    \n",
    "class Workflow:\n",
    "    #contains all of the information needed to understand a single workflow\n",
    "    def __init__(self,round_added = 0,parent = None):\n",
    "        self.next = FinalNode()\n",
    "        self.round_added = round_added\n",
    "        self.copies = 0\n",
    "        # DONE: make sure workflows are being compared based on their IDs (since there may not be consistent parity between naive objects)\n",
    "        self.id = str(uuid(NAMESPACE_DNS,str(self.round_added)+chr(97+self.copies)))\n",
    "        self.parent = parent\n",
    "        \n",
    "    async def start(self,first_inputs):\n",
    "        return await self.next(**first_inputs | {'depth':0})\n",
    "        \n",
    "    def add_node(self,node_class:WorkflowNode,description,prompt,modification):\n",
    "        new_node = node_class(description,prompt,modification)\n",
    "        \n",
    "        if not isinstance(self.next,FinalNode):\n",
    "            current_node = self.next\n",
    "            while not isinstance(current_node.next,FinalNode):\n",
    "                current_node = current_node.next\n",
    "            #print(type(current_node))\n",
    "        else:\n",
    "            current_node = self\n",
    "        \n",
    "        current_node.next = new_node\n",
    "        return self\n",
    "        \n",
    "    def copy(self, round_):\n",
    "        # Create a shallow copy of the current instance\n",
    "        new_workflow = Workflow(round_,self)\n",
    "        new_workflow.next = self.next.copy()\n",
    "        new_workflow.copies = self.copies + 1\n",
    "        # DONE: make sure workflows are being compared based on their IDs (since there may not be consistent parity between naive objects)\n",
    "        new_workflow.id = str(uuid(NAMESPACE_DNS, str(new_workflow.round_added) + chr(97 + new_workflow.copies)))\n",
    "        return new_workflow \n",
    "\n",
    "    def __lt__(self,other):\n",
    "        return self.copies < other.copies\n",
    "    \n",
    "    def extract_chain_info(self):\n",
    "        chain = []\n",
    "        chain_info = []\n",
    "        current_node = self.next\n",
    "        while current_node.next:\n",
    "            chain.append(type(current_node))\n",
    "            chain_info.append(str(current_node))\n",
    "            current_node = current_node.next\n",
    "            \n",
    "        return ' -->> '.join(map(str,chain)),'\\n'.join([':'.join((node,node_info)) for node,node_info in zip(map(str,chain),chain_info)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f910299-a82e-4e63-8d00-a5c335ae64b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#available operators\n",
    "# class GeneratePrompts(WorkflowNode):\n",
    "#     def __init__():\n",
    "#         super().__init__()\n",
    "#     def __call__(self,**kwargs):\n",
    "#         #does something with prev_step and returns it\n",
    "#         llm_client = kwargs['llm_client']\n",
    "#         data = kwargs['data']\n",
    "#         prompt\n",
    "#         results = []\n",
    "#         for instance in data:\n",
    "#             llm_client.chat.completions.create(\n",
    "#                 messages=[\n",
    "#                     messages+[\n",
    "#                         {\"role\":\"user\"},\n",
    "#                         {\"content\":instance}\n",
    "#                     ]\n",
    "#                 ],\n",
    "#                 model='gpt-4o-mini'\n",
    "#             ).messages[0].content\n",
    "#         self.next(messages=results,data=data,\n",
    "#                   llm_client=llm_client)        \n",
    "#     def copy(self):\n",
    "#         return deepcopy(self)\n",
    "    \n",
    "class GenerateText(WorkflowNode):\n",
    "    def __init__(self,description,prompt,modification):\n",
    "        super().__init__(description,prompt,modification)\n",
    "        self.available_kwargs = \"data: the data passed into the node. prompt: the prompt used in the last node, if any.\"\n",
    "        \n",
    "    async def __call__(self,**kwargs):\n",
    "        #does something with prev_step and returns it\n",
    "        llm_client = kwargs.get('llm_client',None)\n",
    "        data = kwargs.get('data',[])\n",
    "        last_prompt = kwargs.get('prompt',[])\n",
    "        depth = kwargs.get('depth',-1)\n",
    "        results = []\n",
    "        #print('in node:',llm_client,';',data)\n",
    "        for instance in data:\n",
    "            result = (await llm_client.chat.completions.create(\n",
    "                messages=[\n",
    "                    {\"role\":\"system\",\"content\":self.prompt.format(**kwargs)},\n",
    "                    {\"role\":\"user\",\"content\":instance}\n",
    "                ],\n",
    "                model='gpt-4o-mini'\n",
    "            )).choices[0].message.content\n",
    "            results.append(result)\n",
    "        if isinstance(self.next,FinalNode):\n",
    "            passthrough_data = results\n",
    "        else:\n",
    "            passthrough_data = []\n",
    "            for d,r in zip(data,results):\n",
    "                passthrough_data.append(\n",
    "                    f\"\"\"Q (Level {depth}):{d}\n",
    "                        A (Level {depth}):{r}\"\"\"\n",
    "                )\n",
    "        return await self.next(data=passthrough_data,llm_client=llm_client,prompt=last_prompt,depth=depth+1 if depth!=-1 else -1)\n",
    "        \n",
    "    def copy(self):\n",
    "        return deepcopy(self)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe8e6bd-57d9-4a02-ba7c-5079f0d60d1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69d054de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DONE: Implement split_data\n",
    "def split_data(dataset,val_ratio=0.2,random_seed=1337):\n",
    "    seed(random_seed)\n",
    "    val_set = []\n",
    "    test_set = []\n",
    "    for datum in dataset:\n",
    "        if random() < val_ratio:\n",
    "            val_set.append(datum)\n",
    "        else:\n",
    "            test_set.append(datum)\n",
    "            \n",
    "    return val_set,test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cec8c07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DONE: Implement determine_variance_threshold\n",
    "# DONE: Implement select_high_variance_instances\n",
    "# TODO: Handle asynchronous running (e.g. each output score set val data i may not correspond with input val data i)\n",
    "def select_high_variance_instances(val_data,score_sets,marginal_variance_tolerance_perc = 0.05):\n",
    "    variances = []\n",
    "    n_data_points = len(score_sets[0])\n",
    "    for i in range(n_data_points):\n",
    "        scores_i = [score_set[i] for score_set in score_sets]\n",
    "        num_scores_i = len(scores_i)\n",
    "        avg_score_i = sum(scores_i)/num_scores_i\n",
    "        sample_variance_i = (1/num_scores_i)*sum((score_i-avg_score_i)**2 for score_i in scores_i)\n",
    "        variances.append(sample_variance_i)\n",
    "        \n",
    "    sorted_variances = sorted(list(set(variances)),reverse=True)\n",
    "    #use elbow method diminishing gains based on marginal_variance_tolerance_perc\n",
    "    last_variance = None\n",
    "    for variance in sorted_variances:\n",
    "        if last_variance is None:\n",
    "            last_variance = variance\n",
    "        else:\n",
    "            perc_change = (variance/last_variance)-1\n",
    "            if perc_change < marginal_variance_tolerance_perc:\n",
    "                return last_variance\n",
    "            last_variance = variance\n",
    "            \n",
    "    return [datum for i,datum in enumerate(val_data) if variances[i]>last_variance],last_variance\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96e3b635",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DONE: Implement select_parent\n",
    "def select_parent(topk_scores,topk_W):\n",
    "    probabilities = calculate_mixed_probabilities(topk_scores) #DONE: Implement calculate_mixed_probabilities\n",
    "    return sample_from_categorical(probabilities,topk_W) #DONE: Implement sample_from_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d73c0bc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#DONE: Implement calculate_mixed_probabilities\n",
    "def calculate_mixed_probabilities(scores,lambda_=0.4,alpha=0.5): #TODO: Determine appropriate values of lambda and alpha from the paper\n",
    "    n = len(scores)\n",
    "    max_score = max(scores)\n",
    "    w = list(e**(alpha*(s_i-max_score)) for s_i in scores)\n",
    "    P_score = (w_i/sum(w) for w_i in w)\n",
    "    P_uniform = (1/n for _ in range(n))\n",
    "    P_mixed = (lambda_ * P_uniform_i + (1-lambda_) * P_score_i for P_score_i,P_uniform_i in zip(P_score,P_uniform))\n",
    "    return P_mixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85f425c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#DONE: Implement sample_from_categorical\n",
    "def sample_from_categorical(probabilities,workflows):\n",
    "    return choices(population=workflows,weights=probabilities,k=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "238d24de-28ac-4e17-9c8f-b28674131ef3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#list(calculate_mixed_probabilities([0.33,0.233]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "263d4239",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DONE: Implement load_context\n",
    "def load_context(parent_workflow,experiences):\n",
    "    #get the experiences related to parent_workflow\n",
    "    #parent_workflow may or may not have modifications\n",
    "    experience_info = []\n",
    "    for round_ in experiences:\n",
    "        if parent_workflow.id in experiences[round_]:\n",
    "            experience_info.append(str(experiences[round_][parent_workflow.id]))\n",
    "    workflow_experiences = '\\n\\n'.join(experience_info)\n",
    "    \n",
    "    #get the node chain visualization and node descriptions parent_workflow implements\n",
    "    chain_viz,chain_descriptions = parent_workflow.extract_chain_info()\n",
    "    \n",
    "    context_string = f\"\"\"\n",
    "        Context for workflow {parent_workflow.id}:\n",
    "        \n",
    "        Workflow node chain visualization:\n",
    "        {chain_viz}\n",
    "        \n",
    "        Descriptions of each node:\n",
    "        {chain_descriptions}\n",
    "        \n",
    "        Trials (experiences) involving this workflow:\n",
    "        {workflow_experiences}\n",
    "    \"\"\"\n",
    "    return context_string\n",
    "    \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa6c480c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DONE: Implement optimize\n",
    "class NodeAdd(BaseModel):\n",
    "    node:str\n",
    "    modification:str\n",
    "    description:str\n",
    "    prompt:str\n",
    "    \n",
    "async def optimize(round_,parent_workflow,context_string,dict_of_valid_operations,llm_client,reward_delay, parent_maturity):\n",
    "    C=  context_string\n",
    "    O = '\\n\\n'.join(map(str,dict_of_valid_operations.keys()))\n",
    "    \n",
    "    optimize_system_prompt = f\"\"\"\n",
    "    You are being given a chance to improve the workflow used to answer user queries.\n",
    "    You will be given information about the workflows as well as information about, and results of, previous attempts (if applicable) to improve the workflow.\n",
    "    You will also be given information about valid operations that can be added to the workflow in order to increase its ability to successfully answer the user query.\n",
    "    \n",
    "    You will be expected to reason step-by-step in order to come to a conclusion about what node (valid operation) to add to the workflow and the prompt that should direct it.\n",
    "    \n",
    "    At the end of your reasoning steps, you should output a single json object in the following format:\n",
    "    {{\"node\":\"<NAME OF NODE>\",\"modification\":\"Add a new <NAME OF NODE> to <AND SO ON>\",\"description\":\"<DESCRIPTION>\",\"prompt:\"<PROMPT>\"}}\n",
    "    where \"<NAME OF NODE>\" is one of given node names. If you fail to choose an existing node name, you will fail your task.\n",
    "    And where <AND SO ON> is where the rest of your explanation should go. If you fail to rationally, simply and clearly describe \n",
    "    your reasoning here, you will fail your task and future optimizations will go poorly.\n",
    "    Third, <DESCRIPTION> is your description of the node's purpose and how it is intended to go about its purpose. This is critical for communicating to yourself in the future about why you created a certain node, so be detailed.\n",
    "    And, finally, <PROMPT>, which is where you exercise your best ability to optimize and improve the results of the next node. If you fail to rationally, simply, and clearly describe\n",
    "    how the next node should interact with its data (which follows from the last node in the current workflow), the optimization task will fail utterly.\n",
    "\n",
    "    Although your communication should be clear, you are allowed to use your resources creatively. For example, you might specify future node expansion if-then instructions in the descriptions,\n",
    "    and/or you may instruct the model to keep part of the previous prompt in the answer so that it's available to later nodes.\n",
    "\n",
    "    Be creative and err on the side of thinking out loud and saying something that isn't useful or doesn't get used rather than not having the idea at all.\n",
    "\n",
    "    In addition, when the node is \"GenerateText\", you are allowed to use the node to generate any output you want, as long as it is within the limits of what is producible by an LLM alone (and not a user).\n",
    "    \n",
    "    Each valid node will have available_kwargs you can include as part of the prompt in hopes the next node will utilize it (e.g. in the next node via: prompt.format(**kwargs)).\n",
    "\n",
    "    Although you may expect your changes to be evaluated at least {reward_delay} times (henceforth referred to as the reward delay) without critical failure, \n",
    "    unless you use nodes that capitalize on the information gained thus far, you will not receive a good evaluation, since your primary goal is to make the workflow fit for responding well within the system. \n",
    "\n",
    "    You have lived through {parent_maturity} evaluations and will die in {max(reward_delay-parent_maturity,0)} evaluations unless you improve.\n",
    "    \n",
    "    Here is how your output is evaluated: On a scale between 0 and 10.\n",
    "    0 is completely irrelevant and/or completely unintelligible or long-winded, and 10 is perfect in both relevance to the original question and its understandability and succinctness. \n",
    "    In between is a continuum of integer grades describing differing levels of imperfection.\n",
    "    \n",
    "    You are BRILLIANT OPTIMIZER.\n",
    "    \"\"\"\n",
    "    \n",
    "    optimize_user_prompt = f\"\"\"\n",
    "    Here is your context:\n",
    "    Workflow information:\n",
    "    {C}\n",
    "    \n",
    "    Valid operations/nodes:\n",
    "    {O}\n",
    "    \"\"\"\n",
    "    \n",
    "#     print(optimize_user_prompt)\n",
    "    \n",
    "    client_response = await llm_client.beta.chat.completions.parse(\n",
    "        messages = [\n",
    "            {\"role\":\"system\",\"content\":optimize_system_prompt},\n",
    "            {\"role\":\"user\"  ,\"content\":optimize_user_prompt}\n",
    "        ],\n",
    "        model='gpt-4o',\n",
    "        response_format=NodeAdd,\n",
    "        temperature = 0.5\n",
    "    )\n",
    "    \n",
    "    nodeadd_obj = client_response.choices[0].message.parsed\n",
    "    \n",
    "    print(nodeadd_obj.dict())\n",
    "    \n",
    "    W_round = parent_workflow.copy(round_).add_node(dict_of_valid_operations.get(nodeadd_obj.node),nodeadd_obj.description,nodeadd_obj.prompt,nodeadd_obj.modification)\n",
    "    return W_round,nodeadd_obj.modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c84e5a8-fc1d-4fa5-a0b8-136234bf7321",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# na = NodeAdd(node = '1',description = '2',prompt = '3',modification = '4')\n",
    "# # na.node = '1'\n",
    "# # na.description = '2'\n",
    "# # na.prompt = '3'\n",
    "# # na.modification = '4'\n",
    "# na.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ba8da5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#DONE: Implement evaluator \n",
    "#will use gpt-4o to assess results (small dataset for now)\n",
    "class Evaluation(BaseModel):\n",
    "    grades:List[int]#conint(ge=0,le=10)\n",
    "        \n",
    "async def evaluate(questions,correct_answers,generated_answers):\n",
    "    \n",
    "    evaluate_system_prompt = \"\"\"\n",
    "    You are being given a chance to evaluate the result of a workflow used to answer user queries.\n",
    "    You will be given the user query, the correct answer, the the answer provided by the workflow.\n",
    "    \n",
    "    At the end of your succinct explanation, you should output only a single json object in the following format:\n",
    "    {\"grades\":List[<GRADE>]}\n",
    "    where <GRADE> is an integer between 0 and 10, where 0 is completely irrelevant and/or completely unintelligible or long-winded, and 10 is perfect in both relevance to the original question and its understandability and succinctness. In between is a continuum of integer grades describing differing levels of imperfection. \n",
    "    Therefore, you are outputting a list of grades\n",
    "    You are EVALUATOR.\n",
    "    \"\"\"\n",
    "    evaluate_user_prompt = \"\"\n",
    "    for i,(q,a,a_hat) in enumerate(zip(questions,correct_answers,generated_answers)):\n",
    "        evaluate_user_prompt+=f\"\"\"\n",
    "        Question {i}:\n",
    "        {q}\n",
    "        Correct Answer {i}:\n",
    "        {a}\n",
    "        Answer generated by workflow {i}:\n",
    "        {a_hat}\n",
    "        \n",
    "        \"\"\"\n",
    "    \n",
    "    client_response = await llm_client.beta.chat.completions.parse(\n",
    "        messages = [\n",
    "            {\"role\":\"system\",\"content\":evaluate_system_prompt},\n",
    "            {\"role\":\"user\"  ,\"content\":evaluate_user_prompt}\n",
    "        ],\n",
    "        model='gpt-4o',\n",
    "        response_format=Evaluation,\n",
    "        temperature = 0.0\n",
    "    )\n",
    "    \n",
    "    evaluation_obj = client_response.choices[0].message.parsed\n",
    "    return evaluation_obj.grades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3b41c7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DONE: Implement execute_workflow_over_data\n",
    "# TODO: Make this asynchronous\n",
    "# TODO: Implement categorical loss\n",
    "async def get_workflow_result(workflow,datum,llm_client):\n",
    "    q,a = datum\n",
    "    a_hat = (await workflow.start({'data':[q],'llm_client':llm_client}))['data']\n",
    "    return a_hat[0]\n",
    "\n",
    "async def execute_workflow_over_data(workflow,evaluator,data,llm_client,batch_size=32):\n",
    "    #scores = []\n",
    "    #costs = []\n",
    "    data_tasks = []\n",
    "    for datum in data:\n",
    "        data_tasks.append(get_workflow_result(workflow,datum,llm_client))\n",
    "         #this works for a continuous loss/gain (e.g. answer quality/lack of), TODO: Implement categorical loss\n",
    "    a_hats = await asyncio.gather(*data_tasks)\n",
    "    num_batches = (len(data) + batch_size) // batch_size\n",
    "    batches = [[] for _ in range(num_batches)]\n",
    "    for i,((q,a),a_hat) in enumerate(zip(data,a_hats)):\n",
    "        batch_i = ((i + batch_size) // batch_size)-1\n",
    "        batches[batch_i].append((q,a,a_hat))\n",
    "    batch_scoring_tasks = []\n",
    "    scores = []\n",
    "    for batch in batches:\n",
    "        questions,answers,generated_answers = zip(*batch)\n",
    "        batch_scoring_tasks.append(evaluator(questions,answers,generated_answers))\n",
    "    scores_by_batch = await asyncio.gather(*batch_scoring_tasks)\n",
    "    for batch_scores in scores_by_batch:\n",
    "        scores.extend(batch_scores)\n",
    "    return scores\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8319b29-7c67-4149-a622-b4663c66ce5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_round_scores(W_round,G,Dv,llm_client):\n",
    "    scores = await execute_workflow_over_data(W_round,G,Dv,llm_client) #DONE: Implement execute_workflow_over_data\n",
    "    round_score = sum(scores)/len(scores) #this works for a continuous loss/gain (e.g. answer quality/lack of), TODO: Implement categorical loss\n",
    "    return round_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68ebce8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "async def get_optimal_workflow(initial_workflow,evaluator,dataset,operators,llm_client,number_of_rounds=20,k=3,early_stopping_rounds=5,scoring_rounds=5,reward_delay=3,early_stop_score=10):\n",
    "    #DONE: Implement evaluator\n",
    "    #Initialize variables\n",
    "    W_0, G, D, N, O, k, n, I = initial_workflow,evaluator,dataset,number_of_rounds,operators,k, \\\n",
    "                                early_stopping_rounds,scoring_rounds\n",
    "    results = []\n",
    "    experiences = Experiences()\n",
    "    topk_W = []\n",
    "    best_W = None\n",
    "    topk_scores = []\n",
    "    best_score = 0\n",
    "    average_score = 0\n",
    "    topk_W_unchanged = 0\n",
    "\n",
    "    keep_alives = {}#{i:None for i in range(reward_delay)}\n",
    "    \n",
    "    #Split dataset\n",
    "    if len(dataset)<50:\n",
    "        Dv,Dt = dataset,dataset\n",
    "    else:\n",
    "        Dv,Dt = split_data(dataset) #DONE: Implement split_data\n",
    "    \n",
    "    #Gather initial scores to determine final validation dataset\n",
    "    score_set_tasks = [execute_workflow_over_data(W_0,G,Dv,llm_client) for _ in range(k)] #DONE: Implement execute_workflow_over_data\n",
    "    score_sets = asyncio.gather(*score_set_tasks)\n",
    "    if len(Dv)>=50:\n",
    "        Dv,variance_threshold = select_high_variance_instances(Dv,score_sets)   #DONE: Implement select_high_variance_instances\n",
    "                                                                        #DONE: Implement determine_variance_threshold\n",
    "    \n",
    "        print(f'{len(Dv)} validation samples selected based on variance threshold {variance_threshold:.2f}')\n",
    "    else:\n",
    "        print(f'All {len(Dv)} validation samples selected for training')\n",
    "    #MAIN LOOP----------------------------------------\n",
    "    #Iterate to improve bestScore\n",
    "    for round_ in (pbar := tqdm(range(N))):\n",
    "        if round_ == 0:\n",
    "            parent = W_0\n",
    "        else:\n",
    "            pbar.set_description(f'Best score:{best_score:.2f} Last round score:{average_score:.2f}')\n",
    "            if len(topk_W) == 1:\n",
    "                parent = topk_W[0]\n",
    "            else:\n",
    "                parent = select_parent(topk_scores,topk_W) #DONE: Implement select_parent\n",
    "        \n",
    "        #Load context for parent and perform optimization forward pass\n",
    "        if round_>0:\n",
    "            parent_maturity = [k for k,v in keep_alives.items() if parent==v[0]]\n",
    "            if parent_maturity:\n",
    "                parent_maturity = parent_maturity[0]\n",
    "            else:\n",
    "                parent_maturity = reward_delay + 1\n",
    "            context = load_context(parent,experiences.experiences) #DONE: Implement load_context\n",
    "            W_round, modification = await optimize(round_,parent,context,O,llm_client,reward_delay,parent_maturity) #DONE: Implement optimize\n",
    "        else:\n",
    "            W_round,modification = parent,''\n",
    "        #Generate validation scores for modified workflow to demonstrate relative performance\n",
    "        round_score_tasks=[]\n",
    "        for i in range(I):\n",
    "            round_score_tasks.append(get_round_scores(W_round,G,Dv,llm_client))\n",
    "        round_scores = await asyncio.gather(*round_score_tasks)\n",
    "        for round_score in round_scores:\n",
    "            results.append((round_,round_score))\n",
    "        \n",
    "        #Capture a new experience for use in future optimization passes by using the modified workflow validation scores as gain\n",
    "        round_scores = [r[1] for r in results if r[0]==round_]\n",
    "        average_score = sum(round_scores)/len(round_scores)\n",
    "        #print(average_score)\n",
    "        experience = experiences.create_experience(W_round,round_,average_score,modification) #DONE: Implement create_experience\n",
    "#         experiences.append(experience) #DONE: Implement Experience(Experiences?) obj in a way that makes retrieval by round easier\n",
    "        \n",
    "        #Save the previous topk_W for the later early-stopping check\n",
    "        prev_topk_W = topk_W\n",
    "        \n",
    "        #Update best W, if applicable this round\n",
    "        if average_score > best_score:\n",
    "            best_score = average_score\n",
    "            best_W = W_round\n",
    "\n",
    "        if reward_delay in keep_alives:\n",
    "            del keep_alives[reward_delay]\n",
    "        keep_alives = {k+1:v for k,v in keep_alives.items()}\n",
    "        keep_alives[0]=(W_round,average_score)\n",
    "\n",
    "        #print(average_score,W_round.extract_chain_info())\n",
    "        \n",
    "        topk_W.append(W_round)\n",
    "        topk_scores.append(average_score)\n",
    "        \n",
    "        #Try to include this round's W_round into topk_W if the W_round's score is within the top k scores\n",
    "        combined = sorted(zip(topk_scores,topk_W),reverse=True)\n",
    "        topk_scores[:],topk_W[:] = zip(*combined)\n",
    "        \n",
    "        #Boot any workflows outside of the top k scores\n",
    "        #if len(topk_scores)>k:\n",
    "        topk_scores = list(topk_scores[:k])\n",
    "        topk_W = list(topk_W[:k])\n",
    "        if round_!=N-1:\n",
    "            topk_W += [keep_alives[k][0] for k in sorted(keep_alives)]\n",
    "            topk_scores += [keep_alives[k][1] for k in sorted(keep_alives)]\n",
    "            \n",
    "        #dedup topk_W/topk_scores\n",
    "        score_by_id = {W.id:score for W,score in zip(topk_W,topk_scores)}\n",
    "        \n",
    "        topk_W = sorted(list(set(topk_W)),key = lambda W:score_by_id[W.id],reverse=True)\n",
    "        topk_scores = [score_by_id[W.id] for W in topk_W]\n",
    "        \n",
    "        #make sure workflows delaying reward \n",
    "        \n",
    "        #stop early if score threshold is reached\n",
    "        if best_score>=early_stop_score:\n",
    "            break\n",
    "        \n",
    "            \n",
    "        #Check if topk_W is the same as the prev topk_W and increment the early stopping counter if so. If not, set counter to 0.\n",
    "        if set([W.id for W in topk_W])==set([prevW.id for prevW in prev_topk_W]):\n",
    "            topk_W_unchanged+=1 #DONE: make sure workflows are being compared based on their IDs \n",
    "                                                    #(since there may not be consistent parity between naive objects)\n",
    "        else:\n",
    "            topk_W_unchanged = 0\n",
    "        \n",
    "        #Stop the workflow improvement early if no new workflows have joined the top k workflows in n rounds\n",
    "        if topk_W_unchanged >= n:\n",
    "            break\n",
    "    #END MAIN LOOP------------------------------------\n",
    "    #return the best workflow and the k-1 next best workflows/the best workflow's score and the k-1 next best workflows' scores\n",
    "    return (best_W,topk_W),(best_score,topk_scores),results,experiences\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3ab4b4d-c679-4fa0-9d8c-299e55e784a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install openai --quiet\n",
    "from openai import AsyncOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e1acc80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "initial_workflow = Workflow()\n",
    "operators = {'GenerateText':GenerateText} #registered nodes to be used in optimization\n",
    "llm_client = AsyncOpenAI(api_key='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "db9d42db-cd88-4de1-b2ac-70cab8f94d29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "qa_dataset = [\n",
    "    (\"Summarize the key themes discussed in a dataset of customer reviews about a new smartphone.\", \"The reviews primarily focus on the phone's excellent camera quality, long battery life, and sleek design. However, there are several complaints about the high price and lack of a headphone jack.\"),\n",
    "    \n",
    "    (\"Perform sentiment analysis on the following dataset of tweets related to a recent product launch: 'This product is amazing, totally worth the money!', 'Disappointed with the quality. Expected more for the price.', 'Solid performance, but a bit overpriced.'\", \"The sentiments expressed in the dataset are mixed: one tweet is positive, one is negative, and the third expresses neutral sentiment about the product's price.\"),\n",
    "    \n",
    "    (\"Translate the following French sentence into English: 'Le ciel est bleu.'\", \"The translation of 'Le ciel est bleu' is 'The sky is blue.'\"),\n",
    "    \n",
    "    (\"In a dataset of email conversations, identify if the following text is spam: 'Congratulations! You’ve won a free trip to the Bahamas. Click here to claim your prize.'\", \"The text is classified as spam based on the pattern of congratulatory messages and a suspicious link.\"),\n",
    "    \n",
    "    (\"Extract all names of people from the following sentence: 'John and Mary went to Paris for a vacation.'\", \"The extracted names are: John, Mary.\"),\n",
    "    \n",
    "    (\"Given a dataset of news articles, answer the following question: 'Who is the current president of the United States?' from the text: 'In 2024, Joe Biden is serving his second term as president.'\", \"The current president of the United States is Joe Biden.\"),\n",
    "    \n",
    "    # New examples\n",
    "    (\"Identify the sentiment of the following review: 'The hotel was beautiful but the service was terrible.'\", \"The sentiment is mixed, with positive feedback on the hotel itself but negative feedback regarding the service.\"),\n",
    "    \n",
    "    (\"Given a dataset of product descriptions, extract the key features from this description: 'This laptop features a 15.6-inch display, Intel i7 processor, 16GB RAM, and a 512GB SSD.'\", \"The key features are: 15.6-inch display, Intel i7 processor, 16GB RAM, 512GB SSD.\"),\n",
    "    \n",
    "    (\"Translate the following Spanish sentence into English: 'Me gusta mucho la comida mexicana.'\", \"The translation of 'Me gusta mucho la comida mexicana' is 'I really like Mexican food.'\"),\n",
    "    \n",
    "    (\"Classify the following text as either a question or a statement: 'What time does the movie start?'\", \"The text is classified as a question.\"),\n",
    "    \n",
    "    (\"Based on the dataset of historical weather reports, answer the following: 'What was the highest temperature recorded in July 2020?'\", \"The highest temperature recorded in July 2020 was 104°F.\"),\n",
    "    \n",
    "    (\"In a dataset of product reviews, identify if the following review is fake or genuine: 'This product is absolutely amazing and changed my life completely! I recommend it to everyone!'\", \"The review is likely fake due to its exaggerated and overly positive language.\")\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c19f33e-8a41-495c-95c3-a7d1e4b1af92",
   "metadata": {},
   "outputs": [],
   "source": [
    "math_dataset = [\n",
    "    (\"What is the sum of 7 and 5?\", \"The sum of 7 and 5 is 12.\"),\n",
    "    \n",
    "    (\"What is the product of 8 and 6?\", \"The product of 8 and 6 is 48.\"),\n",
    "    \n",
    "    (\"If you subtract 9 from 15, what do you get?\", \"15 minus 9 equals 6.\"),\n",
    "    \n",
    "    (\"What is the square root of 81?\", \"The square root of 81 is 9.\"),\n",
    "    \n",
    "    (\"What is 25% of 200?\", \"25% of 200 is 50.\"),\n",
    "    \n",
    "    (\"Solve for x: 5x = 20\", \"x equals 4.\"),\n",
    "    \n",
    "    (\"If a rectangle has a length of 10 units and a width of 4 units, what is its area?\", \"The area of the rectangle is 40 square units.\"),\n",
    "    \n",
    "    (\"What is the value of 2 raised to the power of 5?\", \"2 to the power of 5 is 32.\"),\n",
    "    \n",
    "    (\"How many degrees are in a right angle?\", \"A right angle has 90 degrees.\"),\n",
    "    \n",
    "    (\"If 12 is divided by 3, what is the quotient?\", \"The quotient is 4.\"),\n",
    "    \n",
    "    (\"A car travels 60 miles in 2 hours. What is its average speed in miles per hour?\", \"The average speed is 30 miles per hour.\"),\n",
    "    \n",
    "    (\"What is the perimeter of a square with a side length of 5 units?\", \"The perimeter is 20 units.\"),\n",
    "    \n",
    "    (\"How many centimeters are there in 1 meter?\", \"There are 100 centimeters in 1 meter.\"),\n",
    "    \n",
    "    (\"What is the greatest common divisor (GCD) of 24 and 36?\", \"The GCD of 24 and 36 is 12.\"),\n",
    "    \n",
    "    (\"Convert 0.75 into a fraction in its simplest form.\", \"0.75 as a fraction in simplest form is 3/4.\"),\n",
    "    \n",
    "    (\"If a triangle has angles of 60° and 70°, what is the measure of the third angle?\", \"The third angle measures 50°.\"),\n",
    "    \n",
    "    (\"How many faces does a cube have?\", \"A cube has 6 faces.\"),\n",
    "    \n",
    "    (\"Solve for y: 3y + 7 = 22\", \"y equals 5.\"),\n",
    "    \n",
    "    (\"What is the average of the numbers 4, 8, and 12?\", \"The average is 8.\"),\n",
    "    \n",
    "    (\"If you flip a fair coin, what is the probability of getting heads?\", \"The probability is 1/2.\")\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fd8fd917",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 20 validation samples selected for training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bf19295fec34972b36f971eab8de193",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'node': 'GenerateText', 'modification': 'Add a new GenerateText node to the existing workflow', 'description': \"This node is intended to generate a response based on the input query. The aim is to create a coherent and contextually relevant text output that addresses the user's query effectively. By leveraging the capabilities of the language model, this node will attempt to understand and fulfill the user's request.\", 'prompt': \"Please generate a comprehensive response to the user's query, ensuring that the answer is relevant, clear, and concise. Focus on addressing the key points of the query and providing useful information that aligns with the user's needs.\"}\n"
     ]
    }
   ],
   "source": [
    "(W_star,topk_W),(best_score,topk_scores),results,experiences = await get_optimal_workflow(initial_workflow,evaluate,math_dataset,operators,llm_client,k=2,number_of_rounds=9,early_stop_score = 9.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7f43758e-7035-4696-9698-a7957631168e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(<__main__.Workflow at 0x7fd0f9e951d0>, 9.6),\n",
       " (<__main__.Workflow at 0x7fd0d6b88590>, 0.0)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(topk_W,topk_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "da955c34-520f-4da4-8997-5c79b6a7f92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_nodes = []\n",
    "best_w = topk_W[0]\n",
    "while best_w.next:\n",
    "    best_nodes.append(best_w)\n",
    "    best_w = best_w.next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bc4df32c-1420-43b8-a830-e4da4d2f15c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.Workflow at 0x7fd0f9e951d0>,\n",
       " <__main__.GenerateText at 0x7fd0d61155d0>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "652abd4a-505b-494f-9899-ce054b6500fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'description': \"This node is intended to generate a response based on the input query. The aim is to create a coherent and contextually relevant text output that addresses the user's query effectively. By leveraging the capabilities of the language model, this node will attempt to understand and fulfill the user's request.\",\n",
       "  'prompt': \"Please generate a comprehensive response to the user's query, ensuring that the answer is relevant, clear, and concise. Focus on addressing the key points of the query and providing useful information that aligns with the user's needs.\",\n",
       "  'modification': 'Add a new GenerateText node to the existing workflow',\n",
       "  'next': <__main__.FinalNode at 0x7fd0fa4f0910>,\n",
       "  'available_kwargs': 'data: the data passed into the node. prompt: the prompt used in the last node, if any.'}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(node.__dict__) for node in best_nodes[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "44b7a851-16a8-4df5-be7d-29eb535398f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "q=\"Convert 0.75 into a fraction in its simplest form.\"\n",
    "a=\"0.75 as a fraction in simplest form is 3/4.\"\n",
    "r = await topk_W[0].start({\"data\":[q],\"llm_client\":llm_client})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9a470f83-4d6d-4701-a6dc-c9d06274ecad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['To convert the decimal 0.75 into a fraction, follow these steps:\\n\\n1. **Write down the decimal as a fraction**: \\n   \\\\[\\n   0.75 = \\\\frac{75}{100}\\n   \\\\]\\n\\n2. **Simplify the fraction**: \\n   To simplify \\\\(\\\\frac{75}{100}\\\\), find the greatest common divisor (GCD) of the numerator (75) and the denominator (100). The GCD of 75 and 100 is 25.\\n\\n3. **Divide both the numerator and the denominator by their GCD**:\\n   \\\\[\\n   \\\\frac{75 \\\\div 25}{100 \\\\div 25} = \\\\frac{3}{4}\\n   \\\\]\\n\\nThus, the decimal 0.75 as a fraction in its simplest form is \\\\(\\\\frac{3}{4}\\\\).']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[8]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_hat = r['data']\n",
    "print(a_hat)\n",
    "await evaluate([q],[a],[a_hat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fd67eab9-8e03-444a-b57b-7840f4b72e10",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 20/20 [00:04<00:00,  4.71it/s]\n"
     ]
    }
   ],
   "source": [
    "a_hats = []\n",
    "grades = []\n",
    "async def get_question_result(q,a):\n",
    "    a_hat = (await topk_W[0].start({'data':[q],'llm_client':llm_client}))['data'][0]\n",
    "    g = (await evaluate([q],[a],[a_hat]))[0]\n",
    "    return a_hat,g\n",
    "question_get_tasks = []\n",
    "for q,a in math_dataset:\n",
    "    question_get_tasks.append(get_question_result(q,a))\n",
    "question_task_results = await tqdm_asyncio.gather(*question_get_tasks)\n",
    "a_hats,grades = zip(*question_task_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "af1b6e0a-9735-4dfe-a352-f863fb1cb0d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Question:What is the sum of 7 and 5?\n",
      "    Answer:The sum of 7 and 5 is 12.\n",
      "    Generated Answer:The sum of 7 and 5 is 12.\n",
      "    Grade:10\n",
      "    -----------------------------\n",
      "    \n",
      "\n",
      "    Question:What is the product of 8 and 6?\n",
      "    Answer:The product of 8 and 6 is 48.\n",
      "    Generated Answer:The product of 8 and 6 is 48.\n",
      "    Grade:10\n",
      "    -----------------------------\n",
      "    \n",
      "\n",
      "    Question:If you subtract 9 from 15, what do you get?\n",
      "    Answer:15 minus 9 equals 6.\n",
      "    Generated Answer:If you subtract 9 from 15, you get 6. The calculation is as follows: \n",
      "\n",
      "15 - 9 = 6.\n",
      "    Grade:9\n",
      "    -----------------------------\n",
      "    \n",
      "\n",
      "    Question:What is the square root of 81?\n",
      "    Answer:The square root of 81 is 9.\n",
      "    Generated Answer:The square root of 81 is 9. This is because 9 multiplied by itself (9 x 9) equals 81.\n",
      "    Grade:9\n",
      "    -----------------------------\n",
      "    \n",
      "\n",
      "    Question:What is 25% of 200?\n",
      "    Answer:25% of 200 is 50.\n",
      "    Generated Answer:To calculate 25% of 200, you can use the formula:\n",
      "\n",
      "\\[ \\text{Percentage} = \\left( \\frac{\\text{Percentage Rate}}{100} \\right) \\times \\text{Total Amount} \\]\n",
      "\n",
      "In this case:\n",
      "\n",
      "\\[ 25\\% = \\frac{25}{100} = 0.25 \\]\n",
      "\n",
      "Now, multiply that by 200:\n",
      "\n",
      "\\[ 0.25 \\times 200 = 50 \\]\n",
      "\n",
      "So, 25% of 200 is **50**.\n",
      "    Grade:8\n",
      "    -----------------------------\n",
      "    \n",
      "\n",
      "    Question:Solve for x: 5x = 20\n",
      "    Answer:x equals 4.\n",
      "    Generated Answer:To solve the equation \\(5x = 20\\), follow these steps:\n",
      "\n",
      "1. **Isolate x**: Divide both sides of the equation by 5 to get \\(x\\) by itself.\n",
      "   \n",
      "   \\[\n",
      "   x = \\frac{20}{5}\n",
      "   \\]\n",
      "\n",
      "2. **Calculate**: Perform the division.\n",
      "\n",
      "   \\[\n",
      "   x = 4\n",
      "   \\]\n",
      "\n",
      "Thus, the solution is \\(x = 4\\).\n",
      "    Grade:9\n",
      "    -----------------------------\n",
      "    \n",
      "\n",
      "    Question:If a rectangle has a length of 10 units and a width of 4 units, what is its area?\n",
      "    Answer:The area of the rectangle is 40 square units.\n",
      "    Generated Answer:To find the area of a rectangle, you can use the formula:\n",
      "\n",
      "\\[\n",
      "\\text{Area} = \\text{Length} \\times \\text{Width}\n",
      "\\]\n",
      "\n",
      "For the rectangle with a length of 10 units and a width of 4 units, you would calculate the area as follows:\n",
      "\n",
      "\\[\n",
      "\\text{Area} = 10 \\, \\text{units} \\times 4 \\, \\text{units} = 40 \\, \\text{square units}\n",
      "\\]\n",
      "\n",
      "Therefore, the area of the rectangle is **40 square units**.\n",
      "    Grade:10\n",
      "    -----------------------------\n",
      "    \n",
      "\n",
      "    Question:What is the value of 2 raised to the power of 5?\n",
      "    Answer:2 to the power of 5 is 32.\n",
      "    Generated Answer:The value of 2 raised to the power of 5 is calculated as follows:\n",
      "\n",
      "\\(2^5 = 2 \\times 2 \\times 2 \\times 2 \\times 2 = 32\\).\n",
      "\n",
      "Therefore, \\(2^5 = 32\\).\n",
      "    Grade:9\n",
      "    -----------------------------\n",
      "    \n",
      "\n",
      "    Question:How many degrees are in a right angle?\n",
      "    Answer:A right angle has 90 degrees.\n",
      "    Generated Answer:A right angle measures exactly 90 degrees. This is a fundamental concept in geometry, often used in various fields such as architecture, engineering, and carpentry, where right angles are essential for creating perpendicular lines and structures.\n",
      "    Grade:8\n",
      "    -----------------------------\n",
      "    \n",
      "\n",
      "    Question:If 12 is divided by 3, what is the quotient?\n",
      "    Answer:The quotient is 4.\n",
      "    Generated Answer:When 12 is divided by 3, the quotient is 4. This is because 12 divided by 3 equals 4 (12 ÷ 3 = 4).\n",
      "    Grade:9\n",
      "    -----------------------------\n",
      "    \n",
      "\n",
      "    Question:A car travels 60 miles in 2 hours. What is its average speed in miles per hour?\n",
      "    Answer:The average speed is 30 miles per hour.\n",
      "    Generated Answer:To calculate the average speed of the car, you can use the formula:\n",
      "\n",
      "\\[ \\text{Average Speed} = \\frac{\\text{Total Distance}}{\\text{Total Time}} \\]\n",
      "\n",
      "In this case, the car travels 60 miles in 2 hours. Plugging in the values:\n",
      "\n",
      "\\[ \\text{Average Speed} = \\frac{60 \\text{ miles}}{2 \\text{ hours}} = 30 \\text{ miles per hour} \\]\n",
      "\n",
      "Therefore, the average speed of the car is **30 miles per hour**.\n",
      "    Grade:9\n",
      "    -----------------------------\n",
      "    \n",
      "\n",
      "    Question:What is the perimeter of a square with a side length of 5 units?\n",
      "    Answer:The perimeter is 20 units.\n",
      "    Generated Answer:The perimeter of a square can be calculated using the formula:\n",
      "\n",
      "\\[ \\text{Perimeter} = 4 \\times \\text{side length} \\]\n",
      "\n",
      "For a square with a side length of 5 units, the calculation would be:\n",
      "\n",
      "\\[ \\text{Perimeter} = 4 \\times 5 = 20 \\text{ units} \\]\n",
      "\n",
      "Therefore, the perimeter of the square is 20 units.\n",
      "    Grade:9\n",
      "    -----------------------------\n",
      "    \n",
      "\n",
      "    Question:How many centimeters are there in 1 meter?\n",
      "    Answer:There are 100 centimeters in 1 meter.\n",
      "    Generated Answer:There are 100 centimeters in 1 meter. This conversion is based on the metric system, where 1 meter is defined as being equal to 100 centimeters.\n",
      "    Grade:9\n",
      "    -----------------------------\n",
      "    \n",
      "\n",
      "    Question:What is the greatest common divisor (GCD) of 24 and 36?\n",
      "    Answer:The GCD of 24 and 36 is 12.\n",
      "    Generated Answer:To find the greatest common divisor (GCD) of 24 and 36, we can use the prime factorization method.\n",
      "\n",
      "1. **Prime factorization of 24**:\n",
      "   - 24 can be divided by 2: \\( 24 = 2 \\times 12 \\)\n",
      "   - 12 can be divided by 2: \\( 12 = 2 \\times 6 \\)\n",
      "   - 6 can be divided by 2: \\( 6 = 2 \\times 3 \\)\n",
      "\n",
      "   Therefore, the prime factorization of 24 is \\( 2^3 \\times 3^1 \\).\n",
      "\n",
      "2. **Prime factorization of 36**:\n",
      "   - 36 can be divided by 2: \\( 36 = 2 \\times 18 \\)\n",
      "   - 18 can be divided by 2: \\( 18 = 2 \\times 9 \\)\n",
      "   - 9 can be divided by 3: \\( 9 = 3 \\times 3 \\)\n",
      "\n",
      "   Therefore, the prime factorization of 36 is \\( 2^2 \\times 3^2 \\).\n",
      "\n",
      "3. **Finding the GCD**:\n",
      "   - For each prime, take the lowest power present in both factorizations:\n",
      "     - For 2: the minimum of \\( 2^3 \\) and \\( 2^2 \\) is \\( 2^2 \\).\n",
      "     - For 3: the minimum of \\( 3^1 \\) and \\( 3^2 \\) is \\( 3^1 \\).\n",
      "\n",
      "   Hence, the GCD is:\n",
      "   \\[\n",
      "   2^2 \\times 3^1 = 4 \\times 3 = 12.\n",
      "   \\]\n",
      "\n",
      "Therefore, the greatest common divisor of 24 and 36 is **12**.\n",
      "    Grade:9\n",
      "    -----------------------------\n",
      "    \n",
      "\n",
      "    Question:Convert 0.75 into a fraction in its simplest form.\n",
      "    Answer:0.75 as a fraction in simplest form is 3/4.\n",
      "    Generated Answer:To convert 0.75 into a fraction, follow these steps:\n",
      "\n",
      "1. **Identify the decimal:** 0.75 can be read as \"75 hundredths,\" which means we can express it as the fraction \\(\\frac{75}{100}\\).\n",
      "\n",
      "2. **Simplify the fraction:** We can simplify \\(\\frac{75}{100}\\) by finding the greatest common divisor (GCD) of 75 and 100. The GCD of 75 and 100 is 25.\n",
      "\n",
      "3. **Divide the numerator and denominator by their GCD:**\n",
      "   \\[\n",
      "   \\frac{75 \\div 25}{100 \\div 25} = \\frac{3}{4}\n",
      "   \\]\n",
      "\n",
      "Thus, 0.75, when converted to a fraction in its simplest form, is \\(\\frac{3}{4}\\).\n",
      "    Grade:9\n",
      "    -----------------------------\n",
      "    \n",
      "\n",
      "    Question:If a triangle has angles of 60° and 70°, what is the measure of the third angle?\n",
      "    Answer:The third angle measures 50°.\n",
      "    Generated Answer:To find the measure of the third angle in a triangle, you can use the fact that the sum of the angles in a triangle is always 180°. \n",
      "\n",
      "You already have two angles: 60° and 70°. \n",
      "\n",
      "Here's how you calculate the third angle:\n",
      "\n",
      "1. Add the two known angles together:\n",
      "   \\( 60° + 70° = 130° \\)\n",
      "\n",
      "2. Subtract this sum from 180° to find the third angle:\n",
      "   \\( 180° - 130° = 50° \\)\n",
      "\n",
      "Therefore, the measure of the third angle is **50°**.\n",
      "    Grade:9\n",
      "    -----------------------------\n",
      "    \n",
      "\n",
      "    Question:How many faces does a cube have?\n",
      "    Answer:A cube has 6 faces.\n",
      "    Generated Answer:A cube has six faces. Each face is a square, and they are all congruent to one another. The faces of a cube meet at right angles, and the shape is characterized by its equal edge lengths.\n",
      "    Grade:8\n",
      "    -----------------------------\n",
      "    \n",
      "\n",
      "    Question:Solve for y: 3y + 7 = 22\n",
      "    Answer:y equals 5.\n",
      "    Generated Answer:To solve the equation \\( 3y + 7 = 22 \\), follow these steps:\n",
      "\n",
      "1. **Subtract 7 from both sides** to isolate the term with \\( y \\):\n",
      "\n",
      "   \\[\n",
      "   3y + 7 - 7 = 22 - 7\n",
      "   \\]\n",
      "   \n",
      "   This simplifies to:\n",
      "\n",
      "   \\[\n",
      "   3y = 15\n",
      "   \\]\n",
      "\n",
      "2. **Divide both sides by 3** to solve for \\( y \\):\n",
      "\n",
      "   \\[\n",
      "   \\frac{3y}{3} = \\frac{15}{3}\n",
      "   \\]\n",
      "\n",
      "   This simplifies to:\n",
      "\n",
      "   \\[\n",
      "   y = 5\n",
      "   \\]\n",
      "\n",
      "Thus, the solution is \\( y = 5 \\).\n",
      "    Grade:10\n",
      "    -----------------------------\n",
      "    \n",
      "\n",
      "    Question:What is the average of the numbers 4, 8, and 12?\n",
      "    Answer:The average is 8.\n",
      "    Generated Answer:To find the average of the numbers 4, 8, and 12, you follow these steps:\n",
      "\n",
      "1. **Add the numbers together**: \n",
      "   \\( 4 + 8 + 12 = 24 \\)\n",
      "\n",
      "2. **Count the numbers**: There are 3 numbers in total.\n",
      "\n",
      "3. **Divide the sum by the count of numbers**: \n",
      "   \\( \\frac{24}{3} = 8 \\)\n",
      "\n",
      "Thus, the average of the numbers 4, 8, and 12 is **8**.\n",
      "    Grade:10\n",
      "    -----------------------------\n",
      "    \n",
      "\n",
      "    Question:If you flip a fair coin, what is the probability of getting heads?\n",
      "    Answer:The probability is 1/2.\n",
      "    Generated Answer:When flipping a fair coin, there are two possible outcomes: heads or tails. Since the coin is fair, each outcome is equally likely. Therefore, the probability of getting heads is calculated as follows:\n",
      "\n",
      "\\[\n",
      "\\text{Probability of heads} = \\frac{\\text{Number of favorable outcomes}}{\\text{Total number of outcomes}} = \\frac{1}{2}\n",
      "\\]\n",
      "\n",
      "So, the probability of flipping heads is \\(0.5\\) or \\(50\\%\\).\n",
      "    Grade:9\n",
      "    -----------------------------\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "for (q,a),a_hat,g in zip(math_dataset,a_hats,grades):\n",
    "    print(f\"\"\"\n",
    "    Question:{q}\n",
    "    Answer:{a}\n",
    "    Generated Answer:{a_hat}\n",
    "    Grade:{g}\n",
    "    -----------------------------\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "303c9014",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# workflow_test = Workflow()\n",
    "# workflow_test.add_node(GenerateText,'The GenerateText node is designed to create textual responses based on the input it receives. It can synthesize information, provide explanations, or generate creative content depending on the context of the user query. This node will enhance the workflow by ensuring that the responses are not only relevant but also articulated in a coherent and engaging manner.', \n",
    "#                        \"Based on the user query, generate a detailed and informative text response that addresses the user's needs and provides additional context or examples where necessary.\",\n",
    "#                       'Add a new GenerateText to the workflow')\n",
    "# print(workflow_test.extract_chain_info())\n",
    "# execute_workflow_over_data(workflow_test,evaluate,dataset,llm_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1102224a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0717bd4b-9aac-481e-a99b-ea79ce635d6b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Complexity/cost analysis\n",
    "\n",
    "### Optimization\n",
    "* 1 call per workflow\n",
    "* 1 workflow per round\n",
    "### Workflow\n",
    "* 1 call per node\n",
    "* d nodes per workflow\n",
    "* 1 workflow per scoring round\n",
    "* r_s scoring rounds per round\n",
    "### Evaluation\n",
    "* 1 call per batch of data points per workflow\n",
    "* 1 workflow per scoring round\n",
    "* r_s scoring rounds per round\n",
    "\n",
    "### Total Cost\n",
    "round cost = O + W + E\n",
    "total cost = r_s * (sum(W(d_i<=i) for i in N) + N * (O(1) + r_s * E(D_len,batch_size)) where D_len=data points in dataset and d_i=number of nodes in round i\n",
    "\n",
    "round_cost(where round_num=i) = optimization_call + r_s * evaluation_call * (batch_size + D_len -1 // batch_size) + r_s * node_call * d_i where d_i <= i\n",
    "\n",
    "Since $\\ E[d_0] = 1 $ (starting point), we can write:\n",
    "\n",
    "$E[d_i] = 1 + \\sum_{j=1}^i \\frac{1}{k \\cdot j + 1}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d7f86204",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_expected_cost(N, k, D_len, b, scoring_rounds):\n",
    "    \"\"\"\n",
    "    Calculate the total expected cost over N rounds for a workflow with given complexity/cost analysis,\n",
    "    including batching for evaluation calls, repeated scoring rounds, and rounding of final costs.\n",
    "\n",
    "    Parameters:\n",
    "    N (int): The total number of rounds.\n",
    "    k (int): The number of workflows.\n",
    "    D_len (int): The number of data points in the dataset (for evaluation calls).\n",
    "    b (int): The batch size for evaluation calls.\n",
    "    scoring_rounds (int): The number of scoring rounds per round to form an average.\n",
    "\n",
    "    Returns:\n",
    "    tuple:\n",
    "        - int: The rounded total expected cost across N rounds.\n",
    "        - dict: Rounded breakdown of the number of calls attributed to Optimization, Workflow, and Evaluation.\n",
    "    \"\"\"\n",
    "    # Define constants for cost categories\n",
    "    optimization_call = 1                 # Optimization: 1 call per workflow per round\n",
    "    evaluation_call_per_batch = 1     # Evaluation: 1 call per batch of data points per workflow per scoring round\n",
    "    node_call_per_node = 1                # Workflow: 1 call per node per workflow per scoring round\n",
    "\n",
    "    total_cost = 0                        # Initialize total cost\n",
    "    call_breakdown = {\n",
    "        \"Optimization\": 0,                # Total calls in Optimization\n",
    "        \"Workflow\": 0,                    # Total calls in Workflow (node-related)\n",
    "        \"Evaluation\": 0                   # Total calls in Evaluation (data-related)\n",
    "    }\n",
    "\n",
    "    for i in range(N):\n",
    "        # Calculate the expected number of nodes E[d_i] at round i\n",
    "        expected_nodes = 1 + sum(1 / (k * j + 1) for j in range(1, i + 1))\n",
    "\n",
    "        # Round cost for the current round, factoring in batching and scoring rounds\n",
    "        round_cost = (\n",
    "            optimization_call                          # Optimization cost\n",
    "            + scoring_rounds * evaluation_call_per_batch * ((b+D_len-1) // b)  # Batched Evaluation cost\n",
    "            + scoring_rounds * node_call_per_node * expected_nodes       # Workflow cost per node\n",
    "        )\n",
    "        \n",
    "        # Accumulate total cost\n",
    "        total_cost += round_cost\n",
    "\n",
    "        # Update call breakdown counts\n",
    "        call_breakdown[\"Optimization\"] += optimization_call\n",
    "        call_breakdown[\"Workflow\"] += scoring_rounds * node_call_per_node * expected_nodes\n",
    "        call_breakdown[\"Evaluation\"] += scoring_rounds * ((b+D_len-1) // b) * evaluation_call_per_batch\n",
    "\n",
    "    # Rounding final costs\n",
    "    total_cost = int(total_cost + 1)\n",
    "    call_breakdown[\"Workflow\"] = int(call_breakdown[\"Workflow\"] + 1)\n",
    "    call_breakdown[\"Evaluation\"] = call_breakdown[\"Evaluation\"]\n",
    "    call_breakdown[\"Optimization\"] = call_breakdown[\"Optimization\"]\n",
    "\n",
    "    return total_cost, call_breakdown\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4225c0a4-14ed-4e78-9d08-419227f3bc86",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(131, {'Optimization': 9, 'Workflow': 77, 'Evaluation': 45})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_total_expected_cost(9,2,12,32,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c85668e",
   "metadata": {},
   "source": [
    "### Future Enhancements\n",
    "We can optimize one layer/level of operators.\n",
    "\n",
    "What about two layers of operators? (e.g. operators nested in operators)\n",
    "\n",
    "What about N layers of operators?\n",
    "\n",
    "\n",
    "e.g. can we implement hierarchical optimization so that each and every step in the chain is tightly fit to purpose\n",
    "\n",
    "e.g. can we construct operators from smaller units on the fly?\n",
    "\n",
    "e.g. are there general operators such that these operators can be constructed of these operators at any level of depth\n",
    "\n",
    "\n",
    "We have implemented breadth (operator columns) - can we implement depth (operator rows)?\n",
    "\n",
    "Can we do it just as fast as breadth?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
